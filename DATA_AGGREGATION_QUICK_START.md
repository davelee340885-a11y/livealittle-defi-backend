# æ•¸æ“šèšåˆèˆ‡é©—è­‰ç³»çµ±ï¼šå¿«é€Ÿé–‹å§‹æŒ‡å—

æœ¬æŒ‡å—å¹«åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ LiveaLittle DeFi çš„å¤šæºæ•¸æ“šèšåˆèˆ‡é©—è­‰ç³»çµ±ã€‚

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æ­¥é©Ÿ 1ï¼šå®‰è£ä¾è³´

```bash
pip3 install aiohttp
```

### æ­¥é©Ÿ 2ï¼šé‹è¡Œæ¸¬è©¦

```bash
cd /home/ubuntu/defi_system/backend
python3 multi_source_data_aggregator.py
```

æ‚¨æ‡‰è©²çœ‹åˆ°é¡ä¼¼ä»¥ä¸‹çš„è¼¸å‡ºï¼š

```
==================================================
Fetching consensus price for ETH...
==================================================
âœ… Consensus Price: $4105.13
   Standard Deviation: $1.98
   Data Points: 2
   Sources: coingecko, defillama
```

---

## ğŸ“‹ åŸºæœ¬ç”¨æ³•

### ç²å–å–®å€‹ä»£å¹£çš„å…±è­˜åƒ¹æ ¼

```python
import asyncio
from multi_source_data_aggregator import MultiSourceAggregator

async def main():
    aggregator = MultiSourceAggregator()
    
    # ç²å– ETH åƒ¹æ ¼
    consensus = await aggregator.get_consensus_price("ETH")
    
    if consensus:
        print(f"Price: ${consensus['price']:.2f}")
        print(f"Data Points: {consensus['data_points']}")
        print(f"Sources: {', '.join(consensus['sources'])}")

asyncio.run(main())
```

### æ‰¹é‡ç²å–å¤šå€‹ä»£å¹£åƒ¹æ ¼

```python
import asyncio
from multi_source_data_aggregator import MultiSourceAggregator

async def get_multiple_prices():
    aggregator = MultiSourceAggregator()
    tokens = ["BTC", "ETH", "USDC"]
    
    results = {}
    for token in tokens:
        consensus = await aggregator.get_consensus_price(token)
        if consensus:
            results[token] = consensus['price']
    
    return results

# é‹è¡Œ
prices = asyncio.run(get_multiple_prices())
for token, price in prices.items():
    print(f"{token}: ${price:.2f}")
```

### æª¢æŸ¥æ•¸æ“šè³ªé‡

```python
import asyncio
from multi_source_data_aggregator import MultiSourceAggregator
from data_quality_monitor import DataQualityMonitor

async def check_data_quality():
    aggregator = MultiSourceAggregator()
    monitor = DataQualityMonitor()
    
    # ç²å–æ•¸æ“š
    token = "ETH"
    datapoints = await aggregator.fetch_all_sources(token)
    
    # é©—è­‰
    for dp in datapoints:
        aggregator.validator.validate_datapoint(dp)
    
    # è¨ˆç®—å…±è­˜
    consensus = aggregator.consensus_engine.calculate_consensus(datapoints)
    
    if consensus:
        # ç›£æ§è³ªé‡
        report = monitor.monitor_consensus(
            token, consensus, datapoints, aggregator.sources
        )
        
        print(f"Overall Quality: {report['quality_metrics']['overall_quality']:.3f}")
        print(f"Freshness: {report['quality_metrics']['freshness']:.3f}")
        print(f"Availability: {report['quality_metrics']['availability']:.3f}")

asyncio.run(check_data_quality())
```

---

## ğŸ”§ é›†æˆåˆ° API æœå‹™å™¨

### åœ¨ FastAPI ä¸­ä½¿ç”¨

```python
from fastapi import FastAPI
from multi_source_data_aggregator import MultiSourceAggregator

app = FastAPI()
aggregator = MultiSourceAggregator()

@app.get("/api/v1/price/{token}")
async def get_token_price(token: str):
    consensus = await aggregator.get_consensus_price(token)
    
    if consensus:
        return {
            "token": token,
            "price": consensus["price"],
            "sources": consensus["sources"],
            "data_points": consensus["data_points"],
            "timestamp": consensus["timestamp"]
        }
    else:
        return {"error": "Failed to get price"}, 503
```

### å®šæ™‚æ›´æ–°åƒ¹æ ¼

```python
import asyncio
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from multi_source_data_aggregator import MultiSourceAggregator

aggregator = MultiSourceAggregator()
price_cache = {}

async def update_prices():
    """æ¯ 30 ç§’æ›´æ–°ä¸€æ¬¡åƒ¹æ ¼"""
    tokens = ["BTC", "ETH", "USDC"]
    
    for token in tokens:
        consensus = await aggregator.get_consensus_price(token)
        if consensus:
            price_cache[token] = consensus

# è¨­ç½®èª¿åº¦å™¨
scheduler = AsyncIOScheduler()
scheduler.add_job(update_prices, 'interval', seconds=30)
scheduler.start()

# ä¿æŒé‹è¡Œ
asyncio.get_event_loop().run_forever()
```

---

## ğŸ“Š ç›£æ§å’Œè­¦å ±

### è¨­ç½®è­¦å ±è™•ç†å™¨

```python
from data_quality_monitor import DataQualityMonitor

monitor = DataQualityMonitor()

def handle_alerts(report):
    """è™•ç†è­¦å ±"""
    alerts = report['alerts']
    
    if alerts['system_failure']:
        print("ğŸš¨ CRITICAL: System failure!")
        # ç™¼é€ç·Šæ€¥é€šçŸ¥
    
    if alerts['volatility']:
        print(f"âš ï¸  High volatility detected: {alerts['volatility']}")
        # è¨˜éŒ„åˆ°æ—¥èªŒ
    
    if alerts['divergence']:
        print(f"âš ï¸  Data divergence: {alerts['divergence']}")
        # è§¸ç™¼é¡å¤–é©—è­‰

# ä½¿ç”¨
# report = monitor.monitor_consensus(...)
# handle_alerts(report)
```

---

## ğŸ¯ å¸¸è¦‹å•é¡Œ

### Q: å¦‚ä½•æ·»åŠ æ–°çš„æ•¸æ“šæºï¼Ÿ

å‰µå»ºä¸€å€‹ç¹¼æ‰¿è‡ª `DataSource` çš„æ–°é¡ï¼š

```python
class MyCustomSource(DataSource):
    def __init__(self):
        super().__init__("my_custom_source")
        self.api_url = "https://api.example.com"
    
    async def fetch_price(self, token: str) -> Optional[DataPoint]:
        # å¯¦ç¾ç²å–é‚è¼¯
        pass

# æ·»åŠ åˆ°èšåˆå™¨
aggregator = MultiSourceAggregator()
aggregator.sources.append(MyCustomSource())
```

### Q: å¦‚ä½•èª¿æ•´ç•°å¸¸æª¢æ¸¬çš„é–¾å€¼ï¼Ÿ

åœ¨èª¿ç”¨æª¢æ¸¬å‡½æ•¸æ™‚å‚³å…¥è‡ªå®šç¾©é–¾å€¼ï¼š

```python
# åƒ¹æ ¼æ³¢å‹•é–¾å€¼è¨­ç‚º 5%
volatility_alert = monitor.anomaly_detector.check_price_volatility(
    token, new_price, threshold=0.05
)

# æ•¸æ“šæºåˆ†æ­§é–¾å€¼è¨­ç‚º 3%
divergence_alert = monitor.anomaly_detector.check_data_source_divergence(
    token, datapoints, consensus_price, threshold=0.03
)
```

### Q: å¦‚ä½•è™•ç†æ•¸æ“šæºå¤±æ•ˆï¼Ÿ

ç³»çµ±æœƒè‡ªå‹•æª¢æ¸¬ä¸¦æ¨™è¨˜å¤±æ•ˆçš„æ•¸æ“šæºã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ç‹€æ…‹ï¼š

```python
metrics = aggregator.get_data_quality_metrics()

for source_name, status in metrics['sources_status'].items():
    if not status['available']:
        print(f"âŒ {source_name} is unavailable")
        print(f"   Error count: {status['error_count']}")
```

---

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–

### ä½¿ç”¨ç·©å­˜

```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

async def get_cached_price(token: str):
    # æª¢æŸ¥ç·©å­˜
    cached = redis_client.get(f"price:{token}")
    if cached:
        return json.loads(cached)
    
    # ç²å–æ–°åƒ¹æ ¼
    consensus = await aggregator.get_consensus_price(token)
    
    # ç·©å­˜ 30 ç§’
    if consensus:
        redis_client.setex(
            f"price:{token}", 
            30, 
            json.dumps(consensus)
        )
    
    return consensus
```

### ä¸¦ç™¼ç²å–å¤šå€‹ä»£å¹£

```python
async def get_all_prices(tokens: List[str]):
    tasks = [aggregator.get_consensus_price(token) for token in tokens]
    results = await asyncio.gather(*tasks)
    
    return {
        token: result 
        for token, result in zip(tokens, results) 
        if result is not None
    }
```

---

## ğŸ”— ç›¸é—œæ–‡æª”

- **å®Œæ•´æ–‡æª”**: `DATA_AGGREGATION_AND_VALIDATION_SYSTEM.md`
- **æ¶æ§‹è¨­è¨ˆ**: `data_aggregator_architecture.md`
- **å¯¦ç¾ä»£ç¢¼**: `multi_source_data_aggregator.py`, `data_quality_monitor.py`

---

**æç¤º**ï¼šå»ºè­°åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ä½¿ç”¨æ—¥èªŒè¨˜éŒ„å’Œç›£æ§å·¥å…·ï¼ˆå¦‚ Sentryï¼‰ä¾†è¿½è¹¤ç³»çµ±ç‹€æ…‹å’Œç•°å¸¸ã€‚

